# The Stampede Problem: Understanding and Solving Resource Contention

## Table of Contents
- [What is the Stampede Problem?](#what-is-the-stampede-problem)
- [Demo Implementation Overview](#demo-implementation-overview)
- [Resource Store Implementations](#resource-store-implementations)
- [Problem Scenarios](#problem-scenarios)
- [Visual Flow Diagrams](#visual-flow-diagrams)
- [Implementation Examples](#implementation-examples)
- [Performance Comparison](#performance-comparison)
- [Best Practices](#best-practices)

## What is the Stampede Problem?

The **Stampede Problem** (also known as the **Thundering Herd Problem**) occurs when multiple processes or threads simultaneously compete for the same limited resource, leading to:

- **Performance degradation**
- **Resource exhaustion**
- **Potential deadlocks**
- **Cascading failures**
- **Poor user experience**

### Common Scenarios
- Database connection pool exhaustion
- Cache invalidation and regeneration
- File system access bottlenecks
- API rate limiting issues
- Memory allocation conflicts

## Demo Implementation Overview

This demonstration uses fruit-themed resource examples to illustrate the stampede problem with the following key components:

### Core Data Models

**ResourceExample Class:**
```csharp
public class ResourceExample
{
    public Guid Guid { get; set; } = Guid.NewGuid();
    public string Name { get; set; } = string.Empty;
    
    public override string ToString() => $"{{\"id\":{Guid}, \"name\":{Name}}}";
}
```

**Static Resource Data:**
```csharp
public static string[] ResourceNames = [
    "Apple", "Banana", "Cherry", "Orange", "Grape",
    "Strawberry", "Blueberry", "Pineapple", "Mango", "Peach"
];
```

**Real-time Logging Integration:**
All resource stores support dependency injection of `IRealTimeLogService` for live monitoring:
```csharp
public interface IRealTimeLogService
{
    void Log(string message, LogLevelInternal level = LogLevelInternal.Information, 
             string? source = null, bool highlighted = false);
    void Clear();
    event Action<LogEntry>? LogEntryAdded;
}
```

## Resource Store Implementations

This demo includes four different implementations that demonstrate various aspects of the stampede problem:

### 1. SimpleResourceStore (Baseline)

**Purpose:** Demonstrates normal resource fetching with configurable delays.

```csharp
public class SimpleResourceStore(int delayMs = 200, IRealTimeLogService? logger = null)
{
    public virtual async Task<List<ResourceExample>> GetRandomResourcesAsync()
    {
        var threadId = Thread.CurrentThread.ManagedThreadId;
        _logger?.Log($"Thread {threadId}: Starting to fetch 10 random resources...", 
                    LogLevelInternal.Information, "SimpleResourceStore");
        
        var resources = new List<ResourceExample>();
        for (int i = 0; i < 10; i++)
        {
            var randomName = ResourceStaticData.ResourceNames[_random.Next(ResourceStaticData.ResourceNames.Length)];
            await Task.Delay(_delayMs);
            resources.Add(new ResourceExample { Name = randomName });
        }
        
        _logger?.Log($"Thread {threadId}: Completed fetching 10 resources after {_delayMs}ms", 
                    LogLevelInternal.Information, "SimpleResourceStore");
        return resources;
    }
}
```

**Characteristics:**
- Returns 10 random fruit resources
- Configurable delay simulation (default: 200ms)
- Comprehensive logging with thread ID tracking
- Virtual method for inheritance

### 2. DeadlockProneResourceStore (Deadlock Demonstration)

**Purpose:** Demonstrates how improper locking can cause deadlocks.

```csharp
public class DeadlockProneResourceStore(int delayMs = 300, IRealTimeLogService? logger = null)
    : SimpleResourceStore(delayMs, logger)
{
    private static readonly object _lock1 = new object();
    private static readonly object _lock2 = new object();

    public override async Task<List<ResourceExample>> GetRandomResourcesAsync()
    {
        var threadId = Thread.CurrentThread.ManagedThreadId;
        
        return await Task.Run(async () =>
        {
            if (threadId % 2 == 0)
            {
                // Even threads: lock1 ‚Üí lock2
                lock (_lock1)
                {
                    _logger?.Log($"Thread {threadId}: Acquired lock1, waiting before lock2...", 
                                LogLevelInternal.Warning, "DeadlockProneResourceStore");
                    Thread.Sleep(150);
                    lock (_lock2)
                    {
                        return await base.GetRandomResourcesAsync();
                    }
                }
            }
            else
            {
                // Odd threads: lock2 ‚Üí lock1 (DEADLOCK RISK!)
                lock (_lock2)
                {
                    _logger?.Log($"Thread {threadId}: Acquired lock2, waiting before lock1...", 
                                LogLevelInternal.Warning, "DeadlockProneResourceStore");
                    Thread.Sleep(150);
                    lock (_lock1)
                    {
                        return await base.GetRandomResourcesAsync();
                    }
                }
            }
        });
    }
}
```

**Deadlock Mechanism:**
- Even threads acquire locks in order: `_lock1` ‚Üí `_lock2`
- Odd threads acquire locks in order: `_lock2` ‚Üí `_lock1`
- When both types run simultaneously, circular waiting occurs
- 150ms sleep increases deadlock probability

### 3. CachedResourceStore (Basic Caching - Race Condition Prone)

**Purpose:** Shows basic caching implementation that's vulnerable to race conditions.

```csharp
public class CachedResourceStore : SimpleResourceStore, IDisposable
{
    private readonly IMemoryCache _cache;
    private readonly TimeSpan _cacheExpiration = TimeSpan.FromMinutes(10);
    private const string CACHE_KEY = "RandomResources";

    public override async Task<List<ResourceExample>> GetRandomResourcesAsync()
    {
        var threadId = Thread.CurrentThread.ManagedThreadId;
        
        if (!_cache.TryGetValue(CACHE_KEY, out List<ResourceExample>? cachedResources) || cachedResources == null)
        {
            // RACE CONDITION: Multiple threads can reach here simultaneously
            _logger?.Log($"Thread {threadId}: Cache MISS - Loading resources from store", 
                        LogLevelInternal.Information, "CachedResourceStore", true);
                        
            var resources = await base.GetRandomResourcesAsync(); // Multiple calls possible!
            
            var cacheOptions = new MemoryCacheEntryOptions
            {
                AbsoluteExpirationRelativeToNow = _cacheExpiration,
                Priority = CacheItemPriority.Normal
            };
            _cache.Set(CACHE_KEY, resources, cacheOptions);
            cachedResources = resources;
        }

        _logger?.Log($"Thread {threadId}: Cache HIT - Returning cached resources", 
                    LogLevelInternal.Information, "CachedResourceStore");
        return cachedResources;
    }
}
```

**Race Condition Issues:**
- Multiple threads can simultaneously detect cache miss
- Results in multiple expensive `base.GetRandomResourcesAsync()` calls
- Demonstrates why basic caching isn't thread-safe

### 4. ThreadSafeCachedResourceStore (Optimal Solution)

**Purpose:** Demonstrates the correct, thread-safe caching implementation.

```csharp
public class ThreadSafeCachedResourceStore : SimpleResourceStore, IDisposable
{
    private readonly IMemoryCache _cache;
    private readonly TimeSpan _cacheExpiration = TimeSpan.FromMinutes(10);
    private const string CACHE_KEY = "RandomResources";
    private ConcurrentDictionary<string, SemaphoreSlim> _semaphoreDictionary = [];

    public override async Task<List<ResourceExample>> GetRandomResourcesAsync()
    {
        var threadId = Thread.CurrentThread.ManagedThreadId;

        if (!_cache.TryGetValue(CACHE_KEY, out List<ResourceExample>? cachedResources) || cachedResources == null)
        {
            try
            {
                SemaphoreSlim semaphore = _semaphoreDictionary.GetOrAdd(CACHE_KEY, _ => new(1, 1));
                await semaphore.WaitAsync();
                
                // Double-check pattern
                if (_cache.TryGetValue(CACHE_KEY, out var existingValue))
                {
                    _logger?.Log($"Thread {threadId}: Store data already loaded and populated.", 
                                LogLevelInternal.Information, "ThreadSafeCachedResourceStore");
                    return (List<ResourceExample>?)existingValue!;
                }

                _logger?.Log($"Thread {threadId}: Cache MISS Step forward - Loading resources from store", 
                            LogLevelInternal.Information, "ThreadSafeCachedResourceStore", true);

                var resources = await base.GetRandomResourcesAsync(); // Only one thread executes this
                
                var cacheOptions = new MemoryCacheEntryOptions
                {
                    AbsoluteExpirationRelativeToNow = _cacheExpiration,
                    Priority = CacheItemPriority.Normal
                };
                _cache.Set(CACHE_KEY, resources, cacheOptions);
                cachedResources = resources;
            }
            finally
            {
                if (_semaphoreDictionary.TryGetValue(CACHE_KEY, out var semaphore)) 
                    semaphore.Release();
            }
        }

        _logger?.Log($"Thread {threadId}: Cache HIT - Returning cached resources", 
                    LogLevelInternal.Information, "ThreadSafeCachedResourceStore");
        return cachedResources;
    }
}
```

**Thread Safety Features:**
- Uses `ConcurrentDictionary<string, SemaphoreSlim>` for per-key locking
- Double-check pattern prevents race conditions
- Proper async/await with semaphore handling
- Comprehensive disposal management

## Problem Scenarios

### 1. SimpleResourceStore (Baseline - No Protection)

```mermaid
sequenceDiagram
    participant Client1
    participant Client2
    participant Client3
    participant Client4
    participant Client5
    participant SimpleStore as SimpleResourceStore
    participant Resources as Resource Generation

    Note over Client1,Client5: Multiple clients request same resources simultaneously
    
    Client1->>SimpleStore: GetRandomResourcesAsync()
    Client2->>SimpleStore: GetRandomResourcesAsync()
    Client3->>SimpleStore: GetRandomResourcesAsync()
    Client4->>SimpleStore: GetRandomResourcesAsync()
    Client5->>SimpleStore: GetRandomResourcesAsync()

    Note over SimpleStore,Resources: Each thread generates its own resources
    
    SimpleStore->>Resources: Generate 10 fruit resources (Thread 1)
    SimpleStore->>Resources: Generate 10 fruit resources (Thread 2)
    SimpleStore->>Resources: Generate 10 fruit resources (Thread 3)
    SimpleStore->>Resources: Generate 10 fruit resources (Thread 4)
    SimpleStore->>Resources: Generate 10 fruit resources (Thread 5)

    Resources-->>SimpleStore: Apple, Banana, Cherry... (200ms delay per item)
    Resources-->>SimpleStore: Orange, Grape, Strawberry... (200ms delay per item)
    Resources-->>SimpleStore: Blueberry, Pineapple, Mango... (200ms delay per item)
    Resources-->>SimpleStore: Peach, Apple, Banana... (200ms delay per item)
    Resources-->>SimpleStore: Cherry, Orange, Grape... (200ms delay per item)

    SimpleStore-->>Client1: List<ResourceExample> (10 items)
    SimpleStore-->>Client2: List<ResourceExample> (10 items)
    SimpleStore-->>Client3: List<ResourceExample> (10 items)
    SimpleStore-->>Client4: List<ResourceExample> (10 items)
    SimpleStore-->>Client5: List<ResourceExample> (10 items)

    Note over Client1,Resources: Result: 5x resource generation load, 2000ms+ per request
```

### 2. DeadlockProneResourceStore (Deadlock Demonstration)

```mermaid
sequenceDiagram
    participant Thread1 as Thread 2 (Even)
    participant Thread2 as Thread 3 (Odd)
    participant Thread3 as Thread 4 (Even)
    participant Lock1 as Static Lock1
    participant Lock2 as Static Lock2
    participant DeadlockStore as DeadlockProneResourceStore

    Note over Thread1,Thread3: Even threads vs Odd threads with different lock ordering

    Thread1->>DeadlockStore: GetRandomResourcesAsync()
    Thread2->>DeadlockStore: GetRandomResourcesAsync()
    Thread3->>DeadlockStore: GetRandomResourcesAsync()

    Note over DeadlockStore: Even threads: Lock1 ‚Üí Lock2

    DeadlockStore->>Lock1: Acquire Lock1 (Thread 2)
    DeadlockStore->>Lock2: Acquire Lock2 (Thread 3)
    DeadlockStore->>Lock1: Acquire Lock1 (Thread 4)
    
    Note over DeadlockStore: 150ms sleep creates contention window
    
    DeadlockStore-xLock2: Wait for Lock2 (Thread 2) ‚ùå
    DeadlockStore-xLock1: Wait for Lock1 (Thread 3) ‚ùå

    Note over Thread1,Lock2: DEADLOCK! Thread 2 has Lock1, needs Lock2
    Note over Thread1,Lock2: Thread 3 has Lock2, needs Lock1
    
    rect rgb(255, 200, 200)
        Note over Thread1,Thread3: Circular wait - System hangs indefinitely
    end
```

### 3. CachedResourceStore (Race Condition Prone)

```mermaid
sequenceDiagram
    participant Client1
    participant Client2
    participant Client3
    participant Client4
    participant Client5
    participant CachedStore as CachedResourceStore
    participant Cache as IMemoryCache
    participant SimpleStore as Base SimpleResourceStore

    Note over Client1,Client5: Multiple clients request same resource

    Client1->>CachedStore: GetRandomResourcesAsync()
    Client2->>CachedStore: GetRandomResourcesAsync()
    Client3->>CachedStore: GetRandomResourcesAsync()
    Client4->>CachedStore: GetRandomResourcesAsync()
    Client5->>CachedStore: GetRandomResourcesAsync()

    Note over CachedStore,Cache: All threads check cache simultaneously
    
    CachedStore->>Cache: TryGetValue("RandomResources")
    CachedStore->>Cache: TryGetValue("RandomResources")
    CachedStore->>Cache: TryGetValue("RandomResources")
    CachedStore->>Cache: TryGetValue("RandomResources")
    CachedStore->>Cache: TryGetValue("RandomResources")
    
    Cache-->>CachedStore: false (cache miss) - All threads
    
    Note over CachedStore,SimpleStore: RACE CONDITION: Multiple threads call base method
    
    CachedStore->>SimpleStore: base.GetRandomResourcesAsync() - Thread 1
    CachedStore->>SimpleStore: base.GetRandomResourcesAsync() - Thread 2
    CachedStore->>SimpleStore: base.GetRandomResourcesAsync() - Thread 3

    SimpleStore-->>CachedStore: Resources (Thread 1)
    SimpleStore-->>CachedStore: Resources (Thread 2)
    SimpleStore-->>CachedStore: Resources (Thread 3)

    Note over CachedStore,Cache: Multiple cache sets, last write wins
    CachedStore->>Cache: Set("RandomResources", data)

    CachedStore-->>Client1: Resources
    CachedStore-->>Client2: Resources
    CachedStore-->>Client3: Resources
    CachedStore-->>Client4: Resources
    CachedStore-->>Client5: Resources

    Note over Client1,SimpleStore: Result: 3-5x base calls instead of 1 (race condition)
```

### 4. ThreadSafeCachedResourceStore (Optimal Solution)

```mermaid
sequenceDiagram
    participant Client1
    participant Client2
    participant Client3
    participant Client4
    participant Client5
    participant ThreadSafeStore as ThreadSafeCachedResourceStore
    participant Cache as IMemoryCache
    participant Semaphore as SemaphoreSlim
    participant SimpleStore as Base SimpleResourceStore

    Note over Client1,Client5: Multiple clients request same resource

    Client1->>ThreadSafeStore: GetRandomResourcesAsync()
    Client2->>ThreadSafeStore: GetRandomResourcesAsync()
    Client3->>ThreadSafeStore: GetRandomResourcesAsync()
    Client4->>ThreadSafeStore: GetRandomResourcesAsync()
    Client5->>ThreadSafeStore: GetRandomResourcesAsync()

    Note over ThreadSafeStore,Cache: First check - no lock needed for cache hits
    
    ThreadSafeStore->>Cache: TryGetValue("RandomResources")
    Cache-->>ThreadSafeStore: false (cache miss)

    Note over ThreadSafeStore,Semaphore: Cache miss - acquire semaphore to prevent stampede
    
    ThreadSafeStore->>Semaphore: WaitAsync() - Thread 1
    ThreadSafeStore->>Semaphore: WaitAsync() - Thread 2 (queued)
    ThreadSafeStore->>Semaphore: WaitAsync() - Thread 3 (queued)
    ThreadSafeStore->>Semaphore: WaitAsync() - Thread 4 (queued)
    ThreadSafeStore->>Semaphore: WaitAsync() - Thread 5 (queued)

    Semaphore-->>ThreadSafeStore: ‚úÖ Lock Acquired (Thread 1)
    
    Note over ThreadSafeStore: Double-check pattern
    ThreadSafeStore->>Cache: TryGetValue("RandomResources")
    Cache-->>ThreadSafeStore: false (still miss)

    ThreadSafeStore->>SimpleStore: base.GetRandomResourcesAsync() - Only Thread 1
    SimpleStore-->>ThreadSafeStore: Fresh fruit resources
    ThreadSafeStore->>Cache: Set("RandomResources", data, 10min TTL)
    ThreadSafeStore->>Semaphore: Release()

    Semaphore-->>ThreadSafeStore: ‚úÖ Lock Acquired (Thread 2)
    ThreadSafeStore->>Cache: TryGetValue("RandomResources")
    Cache-->>ThreadSafeStore: true ‚ú® Cache Hit!
    ThreadSafeStore->>Semaphore: Release()

    Note over ThreadSafeStore,Semaphore: Remaining threads also get cache hits

    ThreadSafeStore-->>Client1: Resources (from single base call)
    ThreadSafeStore-->>Client2: Resources (from cache)
    ThreadSafeStore-->>Client3: Resources (from cache)
    ThreadSafeStore-->>Client4: Resources (from cache)
    ThreadSafeStore-->>Client5: Resources (from cache)

    Note over Client1,SimpleStore: Result: Only 1 base call, all threads served efficiently
```

## Visual Flow Diagrams

### Resource Access Patterns

```mermaid
flowchart TD
    A[Multiple Clients] --> B{Cache Available?}
    B -->|No| C[Direct Database Access]
    B -->|Yes| D{Cache Hit?}
    
    C --> E[High Database Load]
    C --> F[Poor Performance]
    C --> G[Potential Deadlocks]
    
    D -->|Hit| H[Fast Response]
    D -->|Miss| I[Single Database Query]
    
    I --> J[Update Cache]
    J --> K[Serve All Requests]
    
    H --> L[Excellent Performance]
    K --> L
    
    style E fill:#ffcccc
    style F fill:#ffcccc
    style G fill:#ffcccc
    style H fill:#ccffcc
    style L fill:#ccffcc
```

### Cache Lifecycle

```mermaid
stateDiagram-v2
    [*] --> Empty: Application Start
    Empty --> Loading: First Request
    Loading --> Populated: Data Fetched
    Populated --> Hit: Subsequent Requests
    Hit --> Hit: Cache Valid
    Populated --> Expired: TTL Reached
    Expired --> Loading: New Request
    Populated --> Empty: Manual Clear
    Loading --> [*]: Application End
    Hit --> [*]: Application End
    Empty --> [*]: Application End
```

## Implementation Examples

### Real-Time Monitoring with IRealTimeLogService

All resource stores in this demo support real-time logging through dependency injection:

```csharp
public interface IRealTimeLogService
{
    event Action<LogEntry>? LogEntryAdded;
    void Log(string message, LogLevelInternal level = LogLevelInternal.Information, 
             string? source = null, bool highlighted = false);
    void Clear();
}

public enum LogLevelInternal
{
    Debug,           // üîç Detailed resource information
    Information,     // ‚ÑπÔ∏è Normal operations
    Warning,         // ‚ö†Ô∏è Potential issues (deadlock attempts)
    Error,           // ‚ùå Critical failures
    HighLighted      // ‚ú® Important cache misses
}
```

### 1. SimpleResourceStore Implementation

**Use Case:** Baseline implementation for performance comparison.

```csharp
public class SimpleResourceStore(int delayMs = 200, IRealTimeLogService? logger = null)
{
    private readonly Random _random = new();
    private readonly int _delayMs = delayMs;
    protected readonly IRealTimeLogService? _logger = logger;

    public virtual async Task<List<ResourceExample>> GetRandomResourcesAsync()
    {
        var threadId = Thread.CurrentThread.ManagedThreadId;
        var message = $"Thread {threadId}: Starting to fetch 10 random resources...";
        
        Console.WriteLine($"[{DateTime.Now:HH:mm:ss.fff}] {message}");
        _logger?.Log(message, LogLevelInternal.Information, "SimpleResourceStore");
        
        var resources = new List<ResourceExample>();
        for (int i = 0; i < 10; i++)
        {
            var randomName = ResourceStaticData.ResourceNames[_random.Next(ResourceStaticData.ResourceNames.Length)];
            await Task.Delay(_delayMs); // Simulate work
            resources.Add(new ResourceExample { Name = randomName });
        }

        var completedMessage = $"Thread {threadId}: Completed fetching 10 resources after {_delayMs}ms";
        Console.WriteLine($"[{DateTime.Now:HH:mm:ss.fff}] {completedMessage}");
        _logger?.Log(completedMessage, LogLevelInternal.Information, "SimpleResourceStore");
        
        return resources;
    }
}
```

**Characteristics:**
- ‚úÖ Simple and predictable
- ‚úÖ Virtual method allows inheritance
- ‚ùå No protection against concurrent access
- ‚ùå Each request generates new resources

### 2. DeadlockProneResourceStore Implementation

**Use Case:** Demonstrates deadlock vulnerabilities in multi-threaded scenarios.

```csharp
public class DeadlockProneResourceStore(int delayMs = 300, IRealTimeLogService? logger = null)
    : SimpleResourceStore(delayMs, logger)
{
    private static readonly object _lock1 = new object();
    private static readonly object _lock2 = new object();

    public override async Task<List<ResourceExample>> GetRandomResourcesAsync()
    {
        var threadId = Thread.CurrentThread.ManagedThreadId;
        
        return await Task.Run(async () =>
        {
            if (threadId % 2 == 0)
            {
                // Even threads: lock1 ‚Üí lock2
                _logger?.Log($"Thread {threadId}: Attempting to acquire lock1...", 
                            LogLevelInternal.Warning, "DeadlockProneResourceStore");
                lock (_lock1)
                {
                    _logger?.Log($"Thread {threadId}: Acquired lock1, waiting before lock2...", 
                                LogLevelInternal.Warning, "DeadlockProneResourceStore");
                    Thread.Sleep(150); // Increase deadlock probability
                    
                    lock (_lock2)
                    {
                        _logger?.Log($"Thread {threadId}: Acquired both locks, delegating to SimpleResourceStore", 
                                    LogLevelInternal.Information, "DeadlockProneResourceStore");
                        return await base.GetRandomResourcesAsync();
                    }
                }
            }
            else
            {
                // Odd threads: lock2 ‚Üí lock1 (DEADLOCK RISK!)
                _logger?.Log($"Thread {threadId}: Attempting to acquire lock2...", 
                            LogLevelInternal.Warning, "DeadlockProneResourceStore");
                lock (_lock2)
                {
                    _logger?.Log($"Thread {threadId}: Acquired lock2, waiting before lock1...", 
                                LogLevelInternal.Warning, "DeadlockProneResourceStore");
                    Thread.Sleep(150); // Increase deadlock probability
                    
                    lock (_lock1)
                    {
                        _logger?.Log($"Thread {threadId}: Acquired both locks, delegating to SimpleResourceStore", 
                                    LogLevelInternal.Information, "DeadlockProneResourceStore");
                        return await base.GetRandomResourcesAsync();
                    }
                }
            }
        });
    }
}
```

**Deadlock Mechanism:**
- üî¥ **Critical Flaw:** Different lock ordering per thread
- ‚ö†Ô∏è Even threads: `_lock1` ‚Üí `_lock2`
- ‚ö†Ô∏è Odd threads: `_lock2` ‚Üí `_lock1`
- üí• **Result:** Circular waiting when both types run simultaneously

### 3. CachedResourceStore Implementation

**Use Case:** Basic caching with race condition vulnerability (educational purpose).

```csharp
public class CachedResourceStore : SimpleResourceStore, IDisposable
{
    private readonly IMemoryCache _cache;
    private readonly TimeSpan _cacheExpiration = TimeSpan.FromMinutes(10);
    private const string CACHE_KEY = "RandomResources";

    public CachedResourceStore(int delayMs = 200, IRealTimeLogService? logger = null)
        : base(delayMs, logger)
    {
        _cache = new MemoryCache(new MemoryCacheOptions());
    }

    public override async Task<List<ResourceExample>> GetRandomResourcesAsync()
    {
        var threadId = Thread.CurrentThread.ManagedThreadId;
        
        if (!_cache.TryGetValue(CACHE_KEY, out List<ResourceExample>? cachedResources) || cachedResources == null)
        {
            // ‚ö†Ô∏è RACE CONDITION: Multiple threads can reach here simultaneously
            var cacheMissMessage = $"Thread {threadId}: Cache MISS - Loading resources from store";
            Console.WriteLine($"[{DateTime.Now:HH:mm:ss.fff}] {cacheMissMessage}");
            _logger?.Log(cacheMissMessage, LogLevelInternal.Information, "CachedResourceStore", true);

            var resources = await base.GetRandomResourcesAsync(); // Multiple expensive calls possible!
            
            var cacheOptions = new MemoryCacheEntryOptions
            {
                AbsoluteExpirationRelativeToNow = _cacheExpiration,
                Priority = CacheItemPriority.Normal
            };
            _cache.Set(CACHE_KEY, resources, cacheOptions);
            cachedResources = resources;
        }

        var cacheHitMessage = $"Thread {threadId}: Cache HIT - Returning cached resources";
        Console.WriteLine($"[{DateTime.Now:HH:mm:ss.fff}] {cacheHitMessage}");
        _logger?.Log(cacheHitMessage, LogLevelInternal.Information, "CachedResourceStore");
        
        return cachedResources;
    }

    public void ClearCache()
    {
        _cache.Remove(CACHE_KEY);
        _logger?.Log("Cache cleared", LogLevelInternal.Information, "CachedResourceStore");
    }

    public void Dispose() => _cache.Dispose();
}
```

**Race Condition Problems:**
- üü° **Issue:** Multiple threads can detect cache miss simultaneously
- üìâ **Result:** Multiple calls to expensive `base.GetRandomResourcesAsync()`
- üéØ **Purpose:** Demonstrates why basic caching isn't sufficient

### 4. ThreadSafeCachedResourceStore Implementation (Recommended)

**Use Case:** Production-ready, thread-safe caching with optimal performance.

```csharp
public class ThreadSafeCachedResourceStore : SimpleResourceStore, IDisposable
{
    private readonly IMemoryCache _cache;
    private readonly TimeSpan _cacheExpiration = TimeSpan.FromMinutes(10);
    private const string CACHE_KEY = "RandomResources";
    private ConcurrentDictionary<string, SemaphoreSlim> _semaphoreDictionary = [];

    public ThreadSafeCachedResourceStore(int delayMs = 200, IRealTimeLogService? logger = null)
        : base(delayMs, logger)
    {
        _cache = new MemoryCache(new MemoryCacheOptions());
    }

    public override async Task<List<ResourceExample>> GetRandomResourcesAsync()
    {
        var threadId = Thread.CurrentThread.ManagedThreadId;

        if (!_cache.TryGetValue(CACHE_KEY, out List<ResourceExample>? cachedResources) || cachedResources == null)
        {
            try
            {
                // Per-key semaphore for granular locking
                SemaphoreSlim semaphore = _semaphoreDictionary.GetOrAdd(CACHE_KEY, _ => new(1, 1));
                
                _logger?.Log($"Thread {threadId}: Cache MISS check waiting to release.", 
                            LogLevelInternal.Information, "ThreadSafeCachedResourceStore");
                            
                await semaphore.WaitAsync();
                
                // üîí Double-check pattern - critical for thread safety
                if (_cache.TryGetValue(CACHE_KEY, out var existingValue))
                {
                    _logger?.Log($"Thread {threadId}: Store data already loaded and populated.", 
                                LogLevelInternal.Information, "ThreadSafeCachedResourceStore");
                    return (List<ResourceExample>?)existingValue!;
                }

                // Only one thread reaches this point
                _logger?.Log($"Thread {threadId}: Cache MISS Step forward - Loading resources from store", 
                            LogLevelInternal.Information, "ThreadSafeCachedResourceStore", true);

                var resources = await base.GetRandomResourcesAsync(); // Single expensive call
                
                var cacheOptions = new MemoryCacheEntryOptions
                {
                    AbsoluteExpirationRelativeToNow = _cacheExpiration,
                    Priority = CacheItemPriority.Normal
                };
                _cache.Set(CACHE_KEY, resources, cacheOptions);
                cachedResources = resources;
            }
            finally
            {
                if (_semaphoreDictionary.TryGetValue(CACHE_KEY, out var semaphore)) 
                    semaphore.Release();
            }
        }

        _logger?.Log($"Thread {threadId}: Cache HIT - Returning cached resources", 
                    LogLevelInternal.Information, "ThreadSafeCachedResourceStore");
        return cachedResources;
    }

    public void ClearCache()
    {
        _cache.Remove(CACHE_KEY);
        _logger?.Log("Cache cleared", LogLevelInternal.Information, "ThreadSafeCachedResourceStore");

        // Clean up semaphores
        foreach (var semaphore in _semaphoreDictionary.Values) 
            semaphore.Dispose();
        _semaphoreDictionary.Clear();
    }

    public void Dispose()
    {
        _cache.Remove(CACHE_KEY);
        foreach (var semaphore in _semaphoreDictionary.Values) 
            semaphore.Dispose();
        _semaphoreDictionary.Clear();
        _cache.Dispose();
    }
}
```

**Thread Safety Features:**
- ‚úÖ **Per-key Semaphore:** `ConcurrentDictionary<string, SemaphoreSlim>` for granular locking
- ‚úÖ **Double-check Pattern:** Prevents race conditions after lock acquisition
- ‚úÖ **Async-friendly:** Uses `SemaphoreSlim.WaitAsync()` instead of `lock`
- ‚úÖ **Resource Management:** Proper disposal of semaphores and cache
- ‚úÖ **Performance:** Fast path for cache hits without locking overhead

## Performance Comparison

### Implementation Comparison Matrix

| Resource Store Implementation     | Concurrent Requests | Resource Generation Calls | Avg Response Time  | Risk Level | Thread Safety | Demo Purpose          |
| --------------------------------- | ------------------- | ------------------------- | ------------------ | ---------- | ------------- | --------------------- |
| **SimpleResourceStore**           | 5                   | 5 (each generates own)    | ~2000ms each       | ÔøΩ None     | ‚ùå None        | Baseline performance  |
| **CachedResourceStore**           | 5                   | 1-5 (race condition)      | ~0-2000ms          | üü° Medium   | ‚ùå Race prone  | Show caching pitfalls |
| **ThreadSafeCachedResourceStore** | 5                   | 1 (guaranteed)            | ~0ms (after first) | üü¢ Low      | ‚úÖ Full        | Production solution   |
| **DeadlockProneResourceStore**    | 5                   | Variable/Infinite         | Timeout/Hangs      | üî¥ Critical | ‚ùå Deadlock    | Deadlock education    |

### Resource Generation Timeline

```mermaid
gantt
    title Resource Generation Calls per Implementation
    dateFormat X
    axisFormat %s
    
    section SimpleResourceStore (No Caching)
    Thread 1 Gen    :0, 2000
    Thread 2 Gen    :0, 2000
    Thread 3 Gen    :0, 2000
    Thread 4 Gen    :0, 2000
    Thread 5 Gen    :0, 2000
    
    section CachedResourceStore (Race Conditions)
    Thread 1 Gen    :0, 2000
    Thread 2 Gen    :0, 2000
    Thread 3 Gen    :0, 2000
    Cache Hit 4     :400, 401
    Cache Hit 5     :600, 601
    
    section ThreadSafeCachedResourceStore (Optimal)
    Thread 1 Gen    :0, 2000
    Cache Hit 2     :200, 201
    Cache Hit 3     :400, 401
    Cache Hit 4     :600, 601
    Cache Hit 5     :800, 801
    
    section DeadlockProneResourceStore (System Hang)
    Thread 1 Lock   :0, 150
    Thread 2 Lock   :0, 150
    Deadlock        :150, 5000
```

### Memory Usage Patterns

```mermaid
pie title Cache Memory Efficiency
    "ThreadSafeCached (1 copy)" : 70
    "CachedResourceStore (1-5 copies)" : 20
    "SimpleResourceStore (no cache)" : 5
    "DeadlockProne (stuck/variable)" : 5
```

### Thread Safety Analysis

```mermaid
flowchart TD
    A[5 Concurrent Requests] --> B{Implementation Type}
    
    B -->|SimpleResourceStore| C[No Coordination]
    B -->|CachedResourceStore| D[Basic Cache Check]
    B -->|ThreadSafeCached| E[Semaphore + Double-Check]
    B -->|DeadlockProne| F[Nested Lock Ordering]
    
    C --> G[5x Resource Generation]
    C --> H[Predictable but Slow]
    
    D --> I[Race Condition]
    D --> J[1-5x Resource Generation]
    D --> K[Inconsistent Performance]
    
    E --> L[Single Resource Generation]
    E --> M[Optimal Performance]
    E --> N[100% Thread Safe]
    
    F --> O[Lock Contention]
    F --> P[Potential Deadlock]
    F --> Q[System Hang Risk]
    
    style G fill:#ffcccc
    style I fill:#ffcccc
    style J fill:#ffcccc
    style K fill:#ffcccc
    style O fill:#ff9999
    style P fill:#ff9999
    style Q fill:#ff9999
    
    style L fill:#ccffcc
    style M fill:#ccffcc
    style N fill:#ccffcc
```

### Real-World Performance Metrics

Based on testing with 10 concurrent threads requesting fruit resources:

#### SimpleResourceStore (Baseline)
```
‚úÖ Characteristics:
- Each thread: 10 items √ó 200ms delay = 2000ms total
- No interference between threads
- Predictable but resource-intensive

‚ùå Problems:
- 10x resource generation (100 total items created)
- High CPU/memory usage
- No optimization
```

#### CachedResourceStore (Race Condition Prone)
```
‚ö†Ô∏è Characteristics:
- First few threads may all miss cache
- Inconsistent results (1-10 resource generations)
- Performance varies based on timing

üéØ Educational Value:
- Demonstrates why basic caching isn't enough
- Shows race condition effects in real-time logs
```

#### ThreadSafeCachedResourceStore (Production Ready)
```
‚úÖ Characteristics:
- Exactly 1 resource generation (10 items total)
- Consistent sub-millisecond response after first request
- Zero race conditions

üöÄ Performance:
- 90%+ reduction in resource generation
- Predictable performance under any load
- Memory efficient
```

#### DeadlockProneResourceStore (Educational Hazard)
```
üíÄ Characteristics:
- Demonstrates classic deadlock scenario
- Even threads: lock1 ‚Üí lock2
- Odd threads: lock2 ‚Üí lock1
- 150ms sleep amplifies deadlock window

‚ö†Ô∏è Educational Purpose:
- Shows importance of consistent lock ordering
- Real-time logs show deadlock progression
- System becomes unresponsive
```

### Cache Effectiveness Metrics

```mermaid
graph LR
    A[Cache Performance] --> B[Hit Rate]
    A --> C[Miss Rate]
    A --> D[Response Time]
    
    B --> E[ThreadSafe: 90%+]
    B --> F[Basic Cache: 60-90%]
    B --> G[No Cache: 0%]
    
    C --> H[ThreadSafe: <10%]
    C --> I[Basic Cache: 10-40%]
    C --> J[No Cache: 100%]
    
    D --> K[ThreadSafe: ~1ms]
    D --> L[Basic Cache: Variable]
    D --> M[No Cache: ~2000ms]
    
    style E fill:#ccffcc
    style F fill:#ffffcc
    style G fill:#ffcccc
    style H fill:#ccffcc
    style I fill:#ffffcc
    style J fill:#ffcccc
    style K fill:#ccffcc
    style L fill:#ffffcc
    style M fill:#ffcccc
```

## Best Practices

### ‚úÖ Do's - Based on Demo Implementations

1. **Use ThreadSafeCachedResourceStore Pattern (Recommended) ‚≠ê**
   ```csharp
   // Per-key semaphore with ConcurrentDictionary
   private ConcurrentDictionary<string, SemaphoreSlim> _semaphoreDictionary = [];
   
   public async Task<List<ResourceExample>> GetRandomResourcesAsync()
   {
       if (!_cache.TryGetValue(CACHE_KEY, out List<ResourceExample>? cachedResources))
       {
           try
           {
               SemaphoreSlim semaphore = _semaphoreDictionary.GetOrAdd(CACHE_KEY, _ => new(1, 1));
               await semaphore.WaitAsync();
               
               // Double-check pattern - critical for thread safety
               if (_cache.TryGetValue(CACHE_KEY, out var existingValue))
                   return (List<ResourceExample>?)existingValue!;
                   
               var resources = await base.GetRandomResourcesAsync();
               _cache.Set(CACHE_KEY, resources, cacheOptions);
               return resources;
           }
           finally
           {
               if (_semaphoreDictionary.TryGetValue(CACHE_KEY, out var semaphore)) 
                   semaphore.Release();
           }
       }
       return cachedResources;
   }
   ```

2. **Implement Comprehensive Logging with IRealTimeLogService**
   ```csharp
   // Real-time logging for monitoring stampede behavior
   _logger?.Log($"Thread {threadId}: Cache MISS - Loading resources from store", 
               LogLevelInternal.Information, "ThreadSafeCachedResourceStore", true);
   
   // Track performance with highlighted important events
   _logger?.Log(cacheMissMessage, LogLevelInternal.Information, "CachedResourceStore", true);
   ```

3. **Use Proper Cache Configuration**
   ```csharp
   // 10-minute expiration with normal priority
   var cacheOptions = new MemoryCacheEntryOptions
   {
       AbsoluteExpirationRelativeToNow = TimeSpan.FromMinutes(10),
       Priority = CacheItemPriority.Normal
   };
   _cache.Set(CACHE_KEY, resources, cacheOptions);
   ```

4. **Implement Proper Resource Disposal**
   ```csharp
   public void Dispose()
   {
       _cache.Remove(CACHE_KEY);
       foreach (var semaphore in _semaphoreDictionary.Values) 
           semaphore.Dispose();
       _semaphoreDictionary.Clear();
       _cache.Dispose();
   }
   ```

5. **Use Dependency Injection for Logging Services**
   ```csharp
   // Primary constructor with optional logger
   public SimpleResourceStore(int delayMs = 200, IRealTimeLogService? logger = null)
   {
       _delayMs = delayMs;
       _logger = logger;
   }
   ```

### ‚ùå Don'ts - Lessons from Demo Problems

1. **Don't use CachedResourceStore pattern without thread safety**
   ```csharp
   // ‚ùå WRONG - Race condition in CachedResourceStore
   if (!_cache.TryGetValue(CACHE_KEY, out var cached) || cached == null)
   {
       // Multiple threads can reach here simultaneously!
       var resources = await base.GetRandomResourcesAsync(); // Multiple expensive calls
       _cache.Set(CACHE_KEY, resources, cacheOptions);
   }
   ```

2. **Don't create deadlock-prone lock hierarchies**
   ```csharp
   // ‚ùå DEADLOCK RISK - Different lock ordering per thread
   if (threadId % 2 == 0)
   {
       lock (_lock1) { lock (_lock2) { /* work */ } } // Even: 1‚Üí2
   }
   else
   {
       lock (_lock2) { lock (_lock1) { /* work */ } } // Odd: 2‚Üí1 - DEADLOCK!
   }
   ```

3. **Don't ignore thread context in logging**
   ```csharp
   // ‚úÖ GOOD - Include thread ID for debugging
   var threadId = Thread.CurrentThread.ManagedThreadId;
   _logger?.Log($"Thread {threadId}: Cache HIT - Returning cached resources", 
               LogLevelInternal.Information, "CachedResourceStore");
   ```

4. **Don't forget virtual methods for inheritance**
   ```csharp
   // ‚úÖ GOOD - Virtual allows DeadlockProneResourceStore override
   public virtual async Task<List<ResourceExample>> GetRandomResourcesAsync()
   ```

5. **Don't use synchronous delays in async contexts**
   ```csharp
   // ‚ùå WRONG - Blocks thread pool
   Thread.Sleep(150);
   
   // ‚úÖ BETTER - Non-blocking delay
   await Task.Delay(_delayMs);
   ```

### ‚ö†Ô∏è Common Thread Safety Mistakes from Demo

```csharp
// ‚ùå WRONG - CachedResourceStore race condition
public async Task<List<ResourceExample>> GetRandomResourcesAsync()
{
    if (!_cache.TryGetValue(CACHE_KEY, out var cached))
        return cached; // ‚Üê Multiple threads can pass here
        
    var resources = await base.GetRandomResourcesAsync(); // ‚Üê Multiple calls!
    _cache.Set(CACHE_KEY, resources);
    return resources;
}

// ‚úÖ CORRECT - ThreadSafeCachedResourceStore pattern
public async Task<List<ResourceExample>> GetRandomResourcesAsync()
{
    if (!_cache.TryGetValue(CACHE_KEY, out var cached))
    {
        try
        {
            await _semaphore.WaitAsync();
            if (_cache.TryGetValue(CACHE_KEY, out cached)) // Double-check
                return cached;
                
            var resources = await base.GetRandomResourcesAsync(); // Only one call
            _cache.Set(CACHE_KEY, resources);
            return resources;
        }
        finally
        {
            _semaphore.Release();
        }
    }
    return cached;
}
```

### Demo-Specific Resource Generation Guidelines

```mermaid
pie title Resource Generation Strategy (10 items per call)
    "ThreadSafe: 1 generation (optimal)" : 70
    "Basic Cache: 1-5 generations (race)" : 20
    "Simple Store: 5 generations (no cache)" : 8
    "Deadlock: Variable/hang" : 2
```

### Fruit Resource Configuration

```csharp
// Static data for consistent demo behavior
public static string[] ResourceNames = [
    "Apple", "Banana", "Cherry", "Orange", "Grape",
    "Strawberry", "Blueberry", "Pineapple", "Mango", "Peach"
];

// Simulated work with configurable delay
for (int i = 0; i < 10; i++)
{
    var randomName = ResourceStaticData.ResourceNames[_random.Next(ResourceStaticData.ResourceNames.Length)];
    await Task.Delay(_delayMs); // Default: 200ms per item
    resources.Add(new ResourceExample { Name = randomName });
}
```

## Monitoring and Observability

### Key Metrics to Track with IRealTimeLogService

1. **Cache Hit Ratio**: `(Cache Hits / Total Requests) * 100`
2. **Resource Generation Calls**: Monitor `base.GetRandomResourcesAsync()` invocations
3. **Thread Contention**: Track thread IDs in real-time logs
4. **Deadlock Detection**: Monitor lock acquisition timeouts
5. **Memory Usage**: Cache size and fruit resource objects

### Real-time Logging Levels in Demo

```mermaid
graph LR
    A[LogLevelInternal] --> B[Debug üîç]
    A --> C[Information ‚ÑπÔ∏è]
    A --> D[Warning ‚ö†Ô∏è]
    A --> E[Error ‚ùå]
    A --> F[HighLighted ‚ú®]
    
    B --> G[Resource details]
    C --> H[Normal operations]
    D --> I[Lock attempts/deadlock risks]
    E --> J[Critical failures]
    F --> K[Important cache misses]
    
    style G fill:#e6f3ff
    style H fill:#e6ffe6
    style I fill:#fff3cd
    style J fill:#f8d7da
    style K fill:#fff0e6
```

### Alert Patterns from Demo

```mermaid
graph LR
    A[Thread Behavior] --> B{Pattern Detection}
    
    B -->|Multiple cache misses| C[üö® Race Condition Alert]
    B -->|Lock wait timeout| D[üö® Deadlock Alert]
    B -->|Consistent cache hits| E[‚úÖ Healthy Performance]
    
    C --> F[Switch to ThreadSafeCachedResourceStore]
    D --> G[Review lock ordering in code]
    E --> H[Monitor for cache expiration]
```

## Conclusion

The Stampede Problem demonstration shows how different caching and locking strategies affect system performance and reliability. This fruit-themed resource demo provides hands-on experience with common concurrency issues.

### Demo Implementation Hierarchy (Best to Worst)

1. **ü•á ThreadSafeCachedResourceStore** - Production-ready with per-key semaphores
2. **ü•à CachedResourceStore** - Educational tool showing race conditions
3. **ü•â SimpleResourceStore** - Clean baseline for performance comparison
4. **üíÄ DeadlockProneResourceStore** - Critical deadlock demonstration

### Key Learnings from Demo

**ThreadSafeCachedResourceStore Benefits:**
- ‚úÖ **Zero Race Conditions**: ConcurrentDictionary + SemaphoreSlim pattern
- ‚úÖ **Optimal Resource Usage**: Exactly 1 fruit generation per cache period
- ‚úÖ **Real-time Monitoring**: IRealTimeLogService integration with thread tracking
- ‚úÖ **Scalable Design**: Per-key locking allows multiple cache keys

**Educational Value:**
- üéØ **CachedResourceStore**: Shows why basic caching has race conditions
- üéØ **DeadlockProneResourceStore**: Demonstrates circular wait deadlocks
- üéØ **Real-time Logs**: Live visualization of thread behavior and contention

### Performance Impact Summary

```
Scenario: 10 concurrent threads requesting fruit resources

SimpleResourceStore:
- 10 threads √ó 10 items √ó 200ms = 20,000ms total work
- Result: Predictable but resource-intensive

CachedResourceStore (Race Condition):
- 1-10 resource generations (timing dependent)
- Result: Inconsistent performance, wasted cycles

ThreadSafeCachedResourceStore (Optimal):
- Exactly 1 resource generation (10 items)
- Result: 90%+ efficiency improvement, zero waste

DeadlockProneResourceStore:
- System hangs with circular lock dependencies
- Result: Demonstrates critical system failure mode
```

### Integration with Blazor Web UI

The demo includes a real-time Blazor interface that shows:
- Live thread logs with color-coded severity levels
- Cache hit/miss statistics
- Deadlock visualization
- Performance metrics comparison

**Key Takeaway**: The `ThreadSafeCachedResourceStore` pattern with `ConcurrentDictionary<string, SemaphoreSlim>` provides optimal performance while maintaining complete thread safety. The double-check pattern ensures no race conditions, and dependency injection of `IRealTimeLogService` enables comprehensive monitoring.

The fruit resource theme makes complex concurrency concepts accessible while providing practical patterns for production systems.

---

*For interactive demonstration, run the Blazor Web UI and observe real-time logging of different stampede scenarios.*
